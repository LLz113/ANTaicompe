# 数据探索部分

```python
item = pd.read_csv(r'E:\竞赛专用\安泰杯--跨境电商算法大赛\Data\安泰杯-跨境电商智能算法大赛\Antai_AE_round1_item_attr_20190626.csv')
train = pd.read_csv(r'E:\竞赛专用\安泰杯--跨境电商算法大赛\Data\安泰杯-跨境电商智能算法大赛\Antai_AE_round1_train_20190626.csv')
test = pd.read_csv(r'E:\竞赛专用\安泰杯--跨境电商算法大赛\Data\安泰杯-跨境电商智能算法大赛\Antai_AE_round1_test_20190626.csv')
submit = pd.read_csv(r'E:\竞赛专用\安泰杯--跨境电商算法大赛\Data\安泰杯-跨境电商智能算法大赛\Antai_AE_round1_submit_20190715.csv')
```

读取数据， 数据分为item--商品数据， train--训练数据 ， test--测试数据



```python
df = pd.concat([train.assign(is_train=1), test.assign(is_train=0)]) #合并训练集和测试集， 训练集添加is_train = 1 的列， 测试集添加is_train = 0的列

df['create_order_time'] = pd.to_datetime(df['create_order_time'])  #标准化时间格式

# 获取日期， 天， 小时数据
df['date'] = df['create_order_time'].dt.date
df['day'] = df['create_order_time'].dt.day
df['hour'] = df['create_order_time'].dt.hour

# 以item_id 为键 合并 用户表和商品表
df = pd.merge(df, item, how='left', on='item_id')
```



为了降低数据文件占用的内存，尽量对某些列进行数据类型的变换， 变换操作如下

```python
memory = df.memory_usage().sum() / 1024**2 
print('Before memory usage of properties dataframe is :', memory, " MB")

dtype_dict = {'buyer_admin_id' : 'int32', 
              'item_id' : 'int32', 
              'store_id' : pd.Int32Dtype(),
              'irank' : 'int16',
              'item_price' : pd.Int16Dtype(),
              'cate_id' : pd.Int16Dtype(),
              'is_train' : 'int8',
              'day' : 'int8',
              'hour' : 'int8',
             }

df = df.astype(dtype_dict)
memory = df.memory_usage().sum() / 1024**2 
print('After memory usage of properties dataframe is :', memory, " MB")
del train,test; gc.collect()
```



```python
%%time
train = pd.read_csv('../data/Antai_AE_round1_train_20190626.csv')
test = pd.read_csv('../data/Antai_AE_round1_test_20190626.csv')
item = pd.read_csv('../data/Antai_AE_round1_item_attr_20190626.csv')
del train, test; gc.collect()
```

保存文件， 上述文件就是我们得到的占用内存最小的文件了。后面所有操作都基于上述文件来做。



```python
# Null 空值统计
for pdf in [df, item]:
    for col in pdf.columns:
        print(col, pdf[col].isnull().sum())
```

缺失值处理是进行数据分析的第一步。对于存在缺失值的列有三种处理方式：填补、删除、以及保留不变。缺失值情况如下图所示

![image-20240529211620536](C:\Users\H\AppData\Roaming\Typora\typora-user-images\image-20240529211620536.png)

通过查看发现，**此类缺失值导致的原因是由于train表中存在item表中不存在的商品id。**



## 数据探查

```python
#此函数的作用是以['is_train', 'buyer_country_id']为基本计算 ['is_train', 'buyer_country_id']+ col 计算所占各组中的比例
def groupby_cnt_ratio(df, col):
    if isinstance(col, str):  #判断col是否是str类型
        col = [col]
    key = ['is_train', 'buyer_country_id'] + col  
    
    # groupby function
    cnt_stat = df.groupby(key).size().to_frame('count')
    ratio_stat = (cnt_stat / cnt_stat.groupby(['is_train', 'buyer_country_id']).sum()).rename(columns={'count':'count_ratio'})
    return pd.merge(cnt_stat, ratio_stat, on=key, how='outer').sort_values(by=['count'], ascending=False)
```





```python
plt.figure(figsize=(8,6))
sns.countplot(x='is_train', data = df, palette=['red', 'blue'], hue='buyer_country_id', order=[1, 0])
plt.xticks(np.arange(2), ('训练集', '测试集'))
plt.xlabel('数据文件')
plt.title('国家编号');
```

查看了训练数据中不同国家的分布。如题所描述， **熟悉国家xx的数据占比达到80%以上**



### 购买记录数

```python
fig, ax = plt.subplots(1, 2 ,figsize=(16,6))
ax[0].set(xlabel='用户记录数')
sns.kdeplot(admin_cnt.loc[(1, 'xx')]['count'].values, ax=ax[0]).set_title('训练集--xx国用户记录数')

ax[1].legend(labels=['训练集', '测试集'], loc="upper right")
ax[1].set(xlabel='用户记录数')
sns.kdeplot(admin_cnt[admin_cnt['count']<50].loc[(1, 'yy')]['count'].values, ax=ax[1]).set_title('yy国用户记录数')
sns.kdeplot(admin_cnt[admin_cnt['count']<50].loc[(0, 'yy')]['count'].values, ax=ax[1]);
```

查看用户的购买记录数量，发现无论是xx还是yy，**购买记录集中在50以内**。但仍有购买记录超过1000条的。



### 商品销量

```python
fig, ax = plt.subplots(2, 1, figsize=(16,12))
sns.barplot(x='item_id', y='销量', data=top_item_plot[top_item_plot['buyer_country_id']=='xx'], 
            order=top_item_plot['item_id'][top_item_plot['buyer_country_id']=='xx'], ax=ax[0], estimator=np.mean).set_title('xx国-TOP热销商品')
sns.barplot(x='item_id', y='销量', hue='is_train', data=top_item_plot[top_item_plot['buyer_country_id']=='yy'], 
            order=top_item_plot['item_id'][top_item_plot['buyer_country_id']=='yy'], ax=ax[1], estimator=np.mean).set_title('yy国-TOP热销商品');
```

![image-20240529212624884](C:\Users\H\AppData\Roaming\Typora\typora-user-images\image-20240529212624884.png)



xx国的热销产品非常明显。**但是yy国中训练集和测试的产品销量有着很大差异。**这是比较令人头疼的地方。因为明显看出，yy国的训练数据是没办法很好的反映出yy国的用户消费规律的。



### 整体商品销量分布

上面发分析可知，训练集的yy部分和测试集的yy部分有一定差异。那么进行整体分析来看看情况。

```python
def text_style_func(pct, allvals):
    absolute = int(pct/100.*np.sum(allvals))
    return "{:.1f}%({:d})".format(pct, absolute)

def pie_param(ax, df, color_palette):
    return ax.pie(df['占比'].values, autopct=lambda pct: text_style_func(pct, df['商品数']), labels = df['销量'], 
                  explode = [0.1]+ np.zeros(len(df)-1).tolist(), pctdistance = 0.7, colors=sns.color_palette(color_palette, 8))

fig, ax = plt.subplots(1, 3, figsize=(16,12))
ax[0].set(xlabel='xx国-商品销量')
ax[0].set(ylabel='xx国-商品数量比例')
pie_param(ax[0], xx_item_order_plot, "coolwarm")
ax[1].set(xlabel='yy国-训练集商品销量')
pie_param(ax[1], yy_item_order_plot_1, "Set3")
ax[2].set(xlabel='yy国测试集集商品销量')
pie_param(ax[2], yy_item_order_plot_0, "Set3");
```

![image-20240529213119601](C:\Users\H\AppData\Roaming\Typora\typora-user-images\image-20240529213119601.png)

不论是哪个国家，有大量产品销售不过10件。



## 不同类别产品销量

```python
cate_cnt = item.groupby(['cate_id']).size().to_frame('count').reset_index()
cate_cnt.sort_values(by=['count'], ascending=False).head(5)
```

![image-20240529213249799](C:\Users\H\AppData\Roaming\Typora\typora-user-images\image-20240529213249799.png)

579 产品销量可谓是冠绝群雄。





不同商店下品类和商品销量似乎不是特别重要。



## 不同日期下的销量

```python
fig, ax = plt.subplots(2, 1, figsize=(16,10))
sns.lineplot(x='date', y='当天销量', hue='buyer_country_id', data=date_cnt[(date_cnt['is_train']==1)], 
            estimator=np.mean, ax=ax[0]).set_title('训练集——每日销量');

sns.lineplot(x='date', y='当天销量', hue='is_train', data=date_cnt[(date_cnt['buyer_country_id']=='yy')], 
            estimator=np.mean, ax=ax[1]).set_title('yy国每日销量');
```

![image-20240529213533537](C:\Users\H\AppData\Roaming\Typora\typora-user-images\image-20240529213533537.png)

两国的销量波动情况非常类似，尤其是右边那个尖峰出，有着明显的销量提升。因此可以考虑当天是什么特殊日期。可以进行特殊处理。

![image-20240529213715402](C:\Users\H\AppData\Roaming\Typora\typora-user-images\image-20240529213715402.png)

图像细化之后，发现，确实两国曲线波动相似，且27号之后波动大致一致。